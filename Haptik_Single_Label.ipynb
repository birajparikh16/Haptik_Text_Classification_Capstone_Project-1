{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "#from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataframe(filename):\n",
    "    df = pd.read_csv(filename, encoding = 'UTF-8')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(X, custom_stop = [], stem = False):\n",
    "    en_stop = get_stop_words('en')\n",
    "    en_stop.extend(custom_stop)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "#     tokenizer = TreebankWordTokenizer()\n",
    "    p_stemmer = PorterStemmer()\n",
    "    list_of_X = X.apply(lambda row: row.lower())\n",
    "    list_of_X = X.apply(lambda row: tokenizer.tokenize(row))\n",
    "    list_of_X = list_of_X.apply(lambda row: [i for i in row if i not in en_stop])\n",
    "    if stem == True:\n",
    "        list_of_X = list_of_X.apply(lambda row: [p_stemmer.stem(i) for i in row])\n",
    "    return list_of_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = create_dataframe('train_data.csv')\n",
    "test = create_dataframe('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_Xy(data):\n",
    "    X = data['message']\n",
    "    y = data.iloc[:,1:].astype(str).replace({'T':1,'F':0})\n",
    "    y = y.idxmax(axis=1)\n",
    "    X = pd.Series(X)\n",
    "    y = pd.Series(y)\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train , y_train = split_Xy(train)\n",
    "X_test , y_test = split_Xy(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_for_cloud = preprocess(X_train, stem = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def create_word_cloud(X):\n",
    "#     text = []\n",
    "#     for sentence in X:\n",
    "#         text.extend(sentence)\n",
    "#     textall = \" \".join(text)\n",
    "#     wordcloud = WordCloud(max_font_size=40).generate(textall)\n",
    "#     plt.imshow(wordcloud, interpolation='bilinear')\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_word_cloud(X_train_for_cloud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train = preprocess(X_train,stem = True, custom_stop = ['hi','api_name','please','help','user_id'])\n",
    "X_test  = preprocess(X_test, stem = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                          [7am, everyday]\n",
       "1                                           [chocol, cake]\n",
       "2              [close, mortic, tenon, joint, door, diment]\n",
       "3                                  [train, eppo, kelambum]\n",
       "4                      [yesterday, cancel, flight, ticket]\n",
       "5                                       [chamg, 12pm, 9pm]\n",
       "6                                    [want, go, rajasthan]\n",
       "7                                                   [room]\n",
       "8                            [can, arrang, flight, ticket]\n",
       "9                                           [kind, remind]\n",
       "10                                 [jamshedpur, jharkhand]\n",
       "11                                     [noidaa, secot, 44]\n",
       "12                                      [flight, spicejet]\n",
       "13                                                  [uber]\n",
       "14                                              [3, 3, 17]\n",
       "15                                            [fare, high]\n",
       "16                       [know, train, run, jalgaon, pune]\n",
       "17               [pl, send, current, statu, train, ticket]\n",
       "18                              [ye, ve, got, remind, now]\n",
       "19                                      [wake, today, 6am]\n",
       "20                           [patli, aligarh, train, week]\n",
       "21                             [can, look, flight, option]\n",
       "22                                     [thrursday, remind]\n",
       "23                                                [remind]\n",
       "24                             [payment, made, ola, money]\n",
       "25                                     [silchar, guwahati]\n",
       "26                                           [five, peopl]\n",
       "27       [like, cancel, wake, call, sun, 05, march, 05,...\n",
       "28           [hey, can, find, nearest, medic, store, task]\n",
       "29                                  [detail, train, 12630]\n",
       "                               ...                        \n",
       "40629                                   [sorri, bro, auto]\n",
       "40630                                        [what, updat]\n",
       "40631                             [can, understand, hindi]\n",
       "40632                                   [locat, churchgat]\n",
       "40633                                                   []\n",
       "40634                                           [u, heart]\n",
       "40635                                          [u, welcom]\n",
       "40636                                     [thank, appreci]\n",
       "40637                                                  [4]\n",
       "40638                                             [anymor]\n",
       "40639                         [abob, offer, still, applic]\n",
       "40640                                       [what, salari]\n",
       "40641                                          [name, pmk]\n",
       "40642                                           [bareilli]\n",
       "40643                      [want, book, privat, jet, task]\n",
       "40644                    [coupon, code, shop, myntra, com]\n",
       "40645                         [can, get, review, gujarati]\n",
       "40646                                         [tat, great]\n",
       "40647                                              [thank]\n",
       "40648                                  [feel, bore, today]\n",
       "40649                   [can, u, tell, call, girl, number]\n",
       "40650                                    [madem, tri, now]\n",
       "40651                       [ntng, els, sir, just, ask, s]\n",
       "40652                                           [bad, guy]\n",
       "40653                                               [chkd]\n",
       "40654                      [add, money, will, expir, date]\n",
       "40655                                             [receip]\n",
       "40656                                              [insur]\n",
       "40657                                      [unabl, search]\n",
       "40658                                    [s, good, experi]\n",
       "Name: message, Length: 40659, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_vect(X_train, X_test):\n",
    "    X_train = [' '.join(sentence) for  sentence in X_train]\n",
    "    X_test = [' '.join(sentence) for  sentence in X_test]\n",
    "    vect = CountVectorizer()\n",
    "    vect.fit(X_train)\n",
    "    X_train_dtm = vect.transform(X_train)\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    return X_train_dtm , X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_dtm , X_test_dtm = create_vect(X_train , X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print X_train_dtm.shape[0] - len(y_train)\n",
    "print X_test_dtm.shape[0] - len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction(X_train_dtm, y_train, X_test_dtm, y_test):\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(X_train_dtm, y_train)\n",
    "    y_predictions = nb.predict(X_test_dtm)\n",
    "    print classification_report(y_predictions, y_test)\n",
    "    return accuracy_score(y_predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.89      0.76      2422\n",
      "          1       0.62      0.84      0.72       604\n",
      "          2       0.66      0.92      0.77       312\n",
      "          3       0.71      0.67      0.69       733\n",
      "          4       0.68      0.90      0.78      1223\n",
      "          5       0.78      0.61      0.69       414\n",
      "          6       0.84      0.82      0.83       884\n",
      "          7       0.42      0.91      0.58       102\n",
      "          8       0.97      0.52      0.68      3306\n",
      "\n",
      "avg / total       0.79      0.74      0.73     10000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.73580000000000001"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(X_train_dtm,y_train,X_test_dtm,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40659, 18836)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm.shape\n",
    "X_test_dtm.shape\n",
    "y_train.shape\n",
    "X_train_dtm.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
